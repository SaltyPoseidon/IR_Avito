{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c242eeb",
   "metadata": {},
   "source": [
    "\n",
    "# 03 — Сборка фичей → LightGBM реранкер → сабмит\n",
    "- Собираем все подготовленные фичи по ключу `['query_id','item_id']`.\n",
    "- Обучаем `LightGBM LGBMRanker (lambdarank)` с hold-out сплитом по `query_id`.\n",
    "- Считаем кастомный `NDCG@10` с декеем `0.97^position`.\n",
    "- Делаем предсказания на тесте и пишем `solution.csv` (пары `query_id,item_id` в порядке убывания скоринга).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bcc380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##%%\n",
    "# Требования:\n",
    "# pip install polars pyarrow lightgbm tqdm numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "378d0e8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:29:41.615611Z",
     "start_time": "2025-09-24T20:29:34.422184Z"
    }
   },
   "source": [
    "\n",
    "##%%\n",
    "import os, json, math\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ML\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    HAS_LGBM = True\n",
    "except Exception as e:\n",
    "    HAS_LGBM = False\n",
    "    print(\"[warn] LightGBM не установлен:\", e)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idine\\PycharmProjects\\Avito_Test\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "c5e9a9b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:29:50.196954Z",
     "start_time": "2025-09-24T20:29:50.174845Z"
    }
   },
   "source": [
    "\n",
    "##%%\n",
    "# ---- Поиск корня проекта ----\n",
    "def find_project_root(start=None):\n",
    "    cur = os.path.abspath(start or os.getcwd())\n",
    "    while True:\n",
    "        has_data = os.path.isdir(os.path.join(cur, \"Data\"))\n",
    "        has_feat = os.path.isdir(os.path.join(cur, \"Features\"))\n",
    "        if has_data and has_feat:\n",
    "            return cur\n",
    "        parent = os.path.dirname(cur)\n",
    "        if parent == cur:\n",
    "            raise RuntimeError(\"Не нашёл корень проекта (ожидаю папки Data/ и Features/).\")\n",
    "        cur = parent\n",
    "\n",
    "BASE_DIR = find_project_root()\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"Data\")\n",
    "FEAT_DIR = os.path.join(BASE_DIR, \"Features\")\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, \"train-dset.parquet\")\n",
    "TEST_PATH  = os.path.join(DATA_DIR, \"test-dset-small.parquet\")\n",
    "\n",
    "# Источники фичей (меняем под наличие файлов)\n",
    "TAB_DIR  = os.path.join(FEAT_DIR, \"table-basic\")\n",
    "COS_TIT_DIR_CAND = [\n",
    "    os.path.join(FEAT_DIR, \"cos-e5-small\"),   # как в твоей структуре\n",
    "    DATA_DIR,                                  # на случай, если лежит рядом (train_cos.parquet / test_cos.parquet)\n",
    "]\n",
    "COS_DESC_BASE_DIR = os.path.join(FEAT_DIR, \"cos-e5-base-desc\")\n",
    "\n",
    "def pick_cos_tit_dir():\n",
    "    for p in COS_TIT_DIR_CAND:\n",
    "        if os.path.exists(os.path.join(p, \"train_cos.parquet\")) and os.path.exists(os.path.join(p, \"test_cos.parquet\")):\n",
    "            return p\n",
    "    raise FileNotFoundError(\"Не нашёл train_cos.parquet/test_cos.parquet ни в Features/cos-e5-small, ни в Data/.\")\n",
    "\n",
    "COS_TIT_DIR = pick_cos_tit_dir()\n",
    "\n",
    "print(\"[paths]\")\n",
    "print(\"BASE_DIR =\", BASE_DIR)\n",
    "print(\"DATA_DIR =\", DATA_DIR)\n",
    "print(\"FEAT_DIR =\", FEAT_DIR)\n",
    "print(\"TAB_DIR  =\", TAB_DIR)\n",
    "print(\"COS_TIT_DIR =\", COS_TIT_DIR)\n",
    "print(\"COS_DESC_BASE_DIR =\", COS_DESC_BASE_DIR)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[paths]\n",
      "BASE_DIR = C:\\Users\\idine\\PycharmProjects\\Avito_Test\n",
      "DATA_DIR = C:\\Users\\idine\\PycharmProjects\\Avito_Test\\Data\n",
      "FEAT_DIR = C:\\Users\\idine\\PycharmProjects\\Avito_Test\\Features\n",
      "TAB_DIR  = C:\\Users\\idine\\PycharmProjects\\Avito_Test\\Features\\table-basic\n",
      "COS_TIT_DIR = C:\\Users\\idine\\PycharmProjects\\Avito_Test\\Features\\cos-e5-small\n",
      "COS_DESC_BASE_DIR = C:\\Users\\idine\\PycharmProjects\\Avito_Test\\Features\\cos-e5-base-desc\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "bcff898c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:29:58.749086Z",
     "start_time": "2025-09-24T20:29:51.059499Z"
    }
   },
   "source": [
    "\n",
    "##%%\n",
    "# ---- Загрузка и сборка ----\n",
    "\n",
    "# Базовые пары и таргет\n",
    "train_base = pl.scan_parquet(TRAIN_PATH).select([\n",
    "    \"query_id\",\"item_id\",\"item_contact\"  # таргет\n",
    "]).collect(streaming=True)\n",
    "\n",
    "test_base  = pl.scan_parquet(TEST_PATH).select([\n",
    "    \"query_id\",\"item_id\"\n",
    "]).collect(streaming=True)\n",
    "\n",
    "# Табличные фичи (без косинусов)\n",
    "train_tab = pl.read_parquet(os.path.join(TAB_DIR, \"train_feats_tab.parquet\"))\n",
    "test_tab  = pl.read_parquet(os.path.join(TAB_DIR, \"test_feats_tab.parquet\"))\n",
    "\n",
    "# Косинус query-title (e5-small) — cos_q_title\n",
    "train_cos_tit = pl.read_parquet(os.path.join(COS_TIT_DIR, \"train_cos.parquet\"))\n",
    "test_cos_tit  = pl.read_parquet(os.path.join(COS_TIT_DIR, \"test_cos.parquet\"))\n",
    "\n",
    "# Косинус query_base ↔ desc_base — cos_q_desc_base (если есть)\n",
    "has_desc_cos = (\n",
    "    os.path.exists(os.path.join(COS_DESC_BASE_DIR, \"train_cos_desc_base.parquet\")) and\n",
    "    os.path.exists(os.path.join(COS_DESC_BASE_DIR, \"test_cos_desc_base.parquet\"))\n",
    ")\n",
    "if has_desc_cos:\n",
    "    train_cos_desc = pl.read_parquet(os.path.join(COS_DESC_BASE_DIR, \"train_cos_desc_base.parquet\"))\n",
    "    test_cos_desc  = pl.read_parquet(os.path.join(COS_DESC_BASE_DIR, \"test_cos_desc_base.parquet\"))\n",
    "else:\n",
    "    train_cos_desc = None\n",
    "    test_cos_desc  = None\n",
    "\n",
    "print(\"[loaded]\",\n",
    "      \"train_base:\", train_base.shape,\n",
    "      \"train_tab:\", train_tab.shape,\n",
    "      \"train_cos_tit:\", train_cos_tit.shape,\n",
    "      \"train_cos_desc:\", None if train_cos_desc is None else train_cos_desc.shape)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_35964\\4190391527.py:5: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  train_base = pl.scan_parquet(TRAIN_PATH).select([\n",
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_35964\\4190391527.py:9: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  test_base  = pl.scan_parquet(TEST_PATH).select([\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loaded] train_base: (7781790, 3) train_tab: (7781790, 56) train_cos_tit: (7781790, 3) train_cos_desc: (7781790, 3)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "9aa445f5",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-09-24T20:38:25.796337100Z",
     "start_time": "2025-09-24T20:30:27.277146Z"
    }
   },
   "source": [
    "\n",
    "##%%\n",
    "# ---- Джойним всё по ключу ['query_id','item_id'] ----\n",
    "def join_all(base_df: pl.DataFrame,\n",
    "             tab_df: pl.DataFrame,\n",
    "             cos_tit_df: pl.DataFrame,\n",
    "             cos_desc_df: pl.DataFrame | None) -> pl.DataFrame:\n",
    "    df = base_df.join(tab_df, on=[\"query_id\",\"item_id\"], how=\"left\")\n",
    "    df = df.join(cos_tit_df, on=[\"query_id\",\"item_id\"], how=\"left\")\n",
    "    if cos_desc_df is not None:\n",
    "        df = df.join(cos_desc_df, on=[\"query_id\",\"item_id\"], how=\"left\")\n",
    "    return df\n",
    "\n",
    "train_full = join_all(train_base, train_tab, train_cos_tit, train_cos_desc)\n",
    "test_full  = join_all(test_base,  test_tab,  test_cos_tit,  test_cos_desc)\n",
    "\n",
    "print(\"[assembled] train_full:\", train_full.shape, \"test_full:\", test_full.shape)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##%%\n",
    "# ---- QC: покрытие пар ----\n",
    "def coverage(pairs: pl.DataFrame, feats: pl.DataFrame, name: str):\n",
    "    miss = pairs.join(feats.select([\"query_id\",\"item_id\"]), on=[\"query_id\",\"item_id\"], how=\"anti\")\n",
    "    print(f\"[coverage] {name}: missing pairs =\", miss.height)\n",
    "\n",
    "coverage(train_base, train_full, \"train\")\n",
    "coverage(test_base,  test_full,  \"test\")\n",
    "\n",
    "# Быстрая проверка NaN/Inf\n",
    "def non_finite_report(df: pl.DataFrame, name: str, cols_sample=20):\n",
    "    num_cols = [c for c, t in df.schema.items() if t.is_numeric() and c not in (\"query_id\",\"item_id\",\"item_contact\")]\n",
    "    sample = num_cols[:cols_sample]\n",
    "    for c in sample:\n",
    "        s = df.get_column(c)\n",
    "        bad = int((~s.is_finite()).sum())\n",
    "        if bad:\n",
    "            print(f\"[non-finite] {name}.{c}: {bad} rows\")\n",
    "\n",
    "non_finite_report(train_full, \"train\")\n",
    "non_finite_report(test_full,  \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5920bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##%%\n",
    "# ---- Подготовка матриц для LGBM ----\n",
    "\n",
    "# Выбираем признаки: все числовые колонки, кроме ключей и таргета\n",
    "drop_cols = {\"query_id\",\"item_id\",\"item_contact\"}\n",
    "feat_cols = [c for c, t in train_full.schema.items() if t.is_numeric() and c not in drop_cols]\n",
    "\n",
    "# Заполняем NaN/Inf нулями\n",
    "def sanitize(df: pl.DataFrame, cols: list[str]) -> np.ndarray:\n",
    "    mat = []\n",
    "    for c in cols:\n",
    "        s = df.get_column(c)\n",
    "        # заменим non-finite на 0\n",
    "        arr = s.fill_null(0.0).to_numpy()\n",
    "        if arr.dtype.kind in (\"i\",\"u\"):\n",
    "            arr = arr.astype(np.float32, copy=False)\n",
    "        else:\n",
    "            # float: заменяем inf/nan\n",
    "            arr = arr.astype(np.float32, copy=False)\n",
    "            arr[~np.isfinite(arr)] = 0.0\n",
    "        mat.append(arr)\n",
    "    X = np.vstack(mat).T.astype(np.float32, copy=False)\n",
    "    return X\n",
    "\n",
    "X_train = sanitize(train_full, feat_cols)\n",
    "y_train = train_full.get_column(\"item_contact\").to_numpy().astype(np.int32)\n",
    "qids    = train_full.get_column(\"query_id\").to_numpy()\n",
    "\n",
    "X_test  = sanitize(test_full, feat_cols)\n",
    "\n",
    "print(\"[matrix] X_train:\", X_train.shape, \"X_test:\", X_test.shape, \"features:\", len(feat_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b7fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##%%\n",
    "# ---- Hold-out сплит по query_id ----\n",
    "rng = np.random.default_rng(42)\n",
    "uniq_q = np.unique(qids)\n",
    "rng.shuffle(uniq_q)\n",
    "n_val = max(1, int(0.1 * len(uniq_q)))\n",
    "val_set = set(uniq_q[:n_val])\n",
    "\n",
    "val_mask = np.isin(qids, list(val_set))\n",
    "tr_mask  = ~val_mask\n",
    "\n",
    "# Упорядочим каждый сабсет по query_id (чтобы группы были подряд)\n",
    "tr_idx = np.where(tr_mask)[0]\n",
    "va_idx = np.where(val_mask)[0]\n",
    "tr_idx = tr_idx[np.argsort(qids[tr_idx], kind=\"mergesort\")]\n",
    "va_idx = va_idx[np.argsort(qids[va_idx], kind=\"mergesort\")]\n",
    "\n",
    "X_tr, y_tr, q_tr = X_train[tr_idx], y_train[tr_idx], qids[tr_idx]\n",
    "X_va, y_va, q_va = X_train[va_idx], y_train[va_idx], qids[va_idx]\n",
    "\n",
    "def group_sizes_from_sorted_ids(ids: np.ndarray) -> np.ndarray:\n",
    "    _, counts = np.unique(ids, return_counts=True)\n",
    "    return counts.astype(int)\n",
    "\n",
    "tr_groups = group_sizes_from_sorted_ids(q_tr)\n",
    "va_groups = group_sizes_from_sorted_ids(q_va)\n",
    "\n",
    "print(f\"[split] train rows={X_tr.shape[0]}, val rows={X_va.shape[0]}, queries train/val={len(np.unique(q_tr))}/{len(np.unique(q_va))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##%%\n",
    "# ---- Кастомный NDCG@10 (0.97^pos) для отчёта ----\n",
    "def calc_dcg_at_k(v: np.ndarray, k: int = 10) -> float:\n",
    "    w = 0.97 ** np.arange(len(v))\n",
    "    return float((v * w)[:k].sum())\n",
    "\n",
    "def calc_ndcg_at_k(labels: np.ndarray, preds: np.ndarray, groups: np.ndarray, k: int = 10) -> float:\n",
    "    # ожидаем, что ids внутри groups отсортированы и group_sizes известны отдельно\n",
    "    order = np.argsort(groups, kind=\"mergesort\")\n",
    "    labels, preds, groups = labels[order], preds[order], groups[order]\n",
    "    uq, counts = np.unique(groups, return_counts=True)\n",
    "    s = 0\n",
    "    scores = []\n",
    "    for c in counts:\n",
    "        sl = slice(s, s+c)\n",
    "        l = labels[sl]; p = preds[sl]\n",
    "        idx = np.argsort(-p, kind=\"mergesort\")\n",
    "        idcg = calc_dcg_at_k(np.sort(l)[::-1], k) + 1e-12\n",
    "        scores.append(calc_dcg_at_k(l[idx], k) / idcg)\n",
    "        s += c\n",
    "    return float(np.mean(scores)) if scores else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d841cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##%%\n",
    "# ---- Обучение LGBM ----\n",
    "if not HAS_LGBM:\n",
    "    raise RuntimeError(\"LightGBM недоступен в окружении. Установи пакет lightgbm.\")\n",
    "\n",
    "params = dict(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[10],\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=127,\n",
    "    min_data_in_leaf=100,\n",
    "    feature_fraction=0.9,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    verbose=-1,\n",
    "    seed=42,\n",
    "    device_type=\"cpu\",  # если есть GPU-версия LGBM, можно поставить \"gpu\"\n",
    ")\n",
    "\n",
    "dtr = lgb.Dataset(X_tr, label=y_tr, group=tr_groups, feature_name=feat_cols)\n",
    "dva = lgb.Dataset(X_va, label=y_va, group=va_groups, feature_name=feat_cols, reference=dtr)\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    dtr,\n",
    "    valid_sets=[dva],\n",
    "    num_boost_round=3000,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(100, verbose=False),\n",
    "        lgb.log_evaluation(100),\n",
    "    ],\n",
    ")\n",
    "print(\"[train] best_iteration:\", model.best_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a479c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##%%\n",
    "# ---- Валидация кастомным NDCG@10 ----\n",
    "preds_va = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "ndcg_val = calc_ndcg_at_k(y_va.astype(float), preds_va.astype(float), q_va, k=10)\n",
    "print(f\"[holdout] custom NDCG@10 (0.97^pos) = {ndcg_val:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eccb6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##%%\n",
    "# ---- Дообучение на всём train (опционально можно пересесть) ----\n",
    "# Для простоты — сразу используем уже обученную модель; при желании можно переобучить на X_train.\n",
    "# Прогноз на тест\n",
    "test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "# Сабмит: сортируем внутри query_id по score убыв.\n",
    "sub = test_full.select([\"query_id\",\"item_id\"]).with_columns(\n",
    "    pl.Series(\"pred\", test_pred)\n",
    ").sort([\"query_id\",\"pred\"], descending=[False, True]).select([\"query_id\",\"item_id\"])\n",
    "\n",
    "SUB_PATH = os.path.join(BASE_DIR, \"solution.csv\")\n",
    "sub.write_csv(SUB_PATH, include_header=True)\n",
    "print(\"[save] submission ->\", SUB_PATH, \"rows=\", sub.height)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
