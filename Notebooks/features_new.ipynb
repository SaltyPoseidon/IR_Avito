{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-19T16:46:02.742022Z",
     "start_time": "2025-09-19T16:46:02.420757Z"
    }
   },
   "source": [
    "#  Feature Engineering notebook (full)\n",
    "#  - Polars-only FE for Avito reranker\n",
    "#  - Uses precomputed cos_q_title (train_cos/test_cos)\n",
    "\n",
    "import os\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# ============== Paths ==============\n",
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"Data\")\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, \"train-dset.parquet\")\n",
    "TEST_PATH = os.path.join(DATA_DIR, \"test-dset-small.parquet\")\n",
    "\n",
    "TRAIN_COS = os.path.join(DATA_DIR, \"train_cos.parquet\")\n",
    "TEST_COS = os.path.join(DATA_DIR, \"test_cos.parquet\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T16:46:12.307472Z",
     "start_time": "2025-09-19T16:46:12.294600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============== Utils ==============\n",
    "\n",
    "def tokenize(col: str) -> pl.Expr:\n",
    "    return (\n",
    "        pl.col(col).cast(pl.Utf8).fill_null(\"\")\n",
    "        .str.to_lowercase()\n",
    "        .str.replace_all(r\"ё\", \"е\")\n",
    "        .str.replace_all(r\"[^0-9\\p{L}]+\", \" \")\n",
    "        .str.strip_chars()\n",
    "        .str.split(\" \")\n",
    "        .list.eval(pl.element().filter(pl.element() != \"\"))\n",
    "    )\n",
    "\n",
    "def add_text_feats(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    df = df.with_columns([\n",
    "        tokenize(\"query_text\").alias(\"query_tokens\"),\n",
    "        tokenize(\"item_title\").alias(\"title_tokens\"),\n",
    "    ])\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"query_tokens\").list.len().alias(\"query_len\"),\n",
    "        pl.col(\"title_tokens\").list.len().alias(\"title_len\"),\n",
    "    ])\n",
    "    # пересечение токенов\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"query_tokens\").list.set_intersection(pl.col(\"title_tokens\")).list.len().alias(\"overlap_q_title\"),\n",
    "    ])\n",
    "    # нормированные меры\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"overlap_q_title\") / (pl.col(\"query_len\")+pl.col(\"title_len\")-pl.col(\"overlap_q_title\")+1e-6)).alias(\"jaccard_q_title\"),\n",
    "        (2*pl.col(\"overlap_q_title\") / (pl.col(\"query_len\")+pl.col(\"title_len\")+1e-6)).alias(\"dice_q_title\"),\n",
    "        (pl.col(\"overlap_q_title\") / (pl.col(\"query_len\")+1)).alias(\"ratio_overlap_title\"),\n",
    "        (pl.col(\"title_len\") - pl.col(\"query_len\")).abs().alias(\"abs_len_diff\"),\n",
    "    ])\n",
    "    # строгая проверка вхождения строки (норм. тексты)\n",
    "    norm_q = (\n",
    "        pl.col(\"query_text\").cast(pl.Utf8).fill_null(\"\").str.to_lowercase()\n",
    "        .str.replace_all(r\"ё\",\"е\").str.replace_all(r\"[^0-9\\p{L}]+\",\" \").str.strip_chars()\n",
    "    )\n",
    "    norm_t = (\n",
    "        pl.col(\"item_title\").cast(pl.Utf8).fill_null(\"\").str.to_lowercase()\n",
    "        .str.replace_all(r\"ё\",\"е\").str.replace_all(r\"[^0-9\\p{L}]+\",\" \").str.strip_chars()\n",
    "    )\n",
    "    df = df.with_columns([\n",
    "        norm_q.alias(\"__qnorm\"), norm_t.alias(\"__tnorm\"),\n",
    "        (pl.col(\"query_text\").fill_null(\"\") != \"\").alias(\"has_query_text\"),\n",
    "        (pl.col(\"item_title\").fill_null(\"\") != \"\").alias(\"has_title\"),\n",
    "    ]).with_columns([\n",
    "        pl.col(\"__tnorm\").str.contains(pl.col(\"__qnorm\")).fill_null(False).alias(\"title_contains_query\")\n",
    "    ]).drop([\"__qnorm\",\"__tnorm\"])\n",
    "    return df"
   ],
   "id": "4eb0cc4f3a498b92",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T16:46:17.621662Z",
     "start_time": "2025-09-19T16:46:17.608498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_global_freqs(train_lf: pl.LazyFrame, test_lf: pl.LazyFrame) -> dict[str, pl.DataFrame]:\n",
    "    both = pl.concat([train_lf, test_lf])\n",
    "    freq_cat  = both.select(\"item_cat_id\").group_by(\"item_cat_id\").agg(pl.len().alias(\"freq_item_cat\"))\n",
    "    freq_mcat = both.select(\"item_mcat_id\").group_by(\"item_mcat_id\").agg(pl.len().alias(\"freq_item_mcat\"))\n",
    "    freq_loc  = both.select(\"item_loc\").group_by(\"item_loc\").agg(pl.len().alias(\"freq_item_loc\"))\n",
    "    return {\n",
    "        \"cat\":  freq_cat.collect(streaming=True),\n",
    "        \"mcat\": freq_mcat.collect(streaming=True),\n",
    "        \"loc\":  freq_loc.collect(streaming=True)\n",
    "    }"
   ],
   "id": "f696d4396c32320d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T16:48:40.115440Z",
     "start_time": "2025-09-19T16:48:40.102636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_basic_feats(df: pl.DataFrame, cos_df: pl.DataFrame, freqs: dict[str, pl.DataFrame]) -> pl.DataFrame:\n",
    "    # косинус\n",
    "    df = df.join(cos_df, on=[\"query_id\",\"item_id\"], how=\"left\")\n",
    "\n",
    "    # совпадения категорий/локаций\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"query_cat\")==pl.col(\"item_cat_id\")).cast(pl.Int8).alias(\"same_cat\"),\n",
    "        (pl.col(\"query_mcat\")==pl.col(\"item_mcat_id\")).cast(pl.Int8).alias(\"same_mcat\"),\n",
    "        (pl.col(\"query_loc\")==pl.col(\"item_loc\")).cast(pl.Int8).alias(\"same_loc\"),\n",
    "    ])\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"same_cat\") & pl.col(\"same_mcat\") & pl.col(\"same_loc\")).cast(pl.Int8).alias(\"triple_match\"),\n",
    "        (pl.col(\"same_cat\") & pl.col(\"same_loc\")).cast(pl.Int8).alias(\"same_cat_loc\"),\n",
    "        (pl.col(\"query_mcat\").is_null()).cast(pl.Int8).alias(\"is_query_mcat_missing\"),\n",
    "    ])\n",
    "\n",
    "    # частоты\n",
    "    df = df.join(freqs[\"cat\"],  on=\"item_cat_id\",  how=\"left\")\n",
    "    df = df.join(freqs[\"mcat\"], on=\"item_mcat_id\", how=\"left\")\n",
    "    df = df.join(freqs[\"loc\"],  on=\"item_loc\",     how=\"left\")\n",
    "    for c in [\"freq_item_cat\",\"freq_item_mcat\",\"freq_item_loc\"]:\n",
    "        if c in df.columns:\n",
    "            df = df.with_columns(pl.col(c).fill_null(0).cast(pl.Int32))\n",
    "\n",
    "    # цена: клип/лог/пер-запросные агрегаты/ранг/кос-группа\n",
    "    p99 = float(df.select(pl.col(\"price\").quantile(0.99)).item())\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"price\").clip(0, p99).alias(\"price_clip\"),\n",
    "        pl.col(\"price\").clip(0, p99).log1p().alias(\"price_log1p\"),\n",
    "        (pl.col(\"price\")==0).cast(pl.Int8).alias(\"price_is_zero\"),\n",
    "    ])\n",
    "    q_price_aggs = df.group_by(\"query_id\").agg([\n",
    "        pl.col(\"price_clip\").median().alias(\"q_price_median\"),\n",
    "        pl.col(\"price_clip\").mean().alias(\"q_price_mean\"),\n",
    "        pl.col(\"price_clip\").std(ddof=0).fill_null(0.0).alias(\"q_price_std\"),\n",
    "        pl.len().alias(\"n_items_in_query\"),\n",
    "        pl.col(\"cos_q_title\").max().alias(\"max_cos_in_query\"),\n",
    "    ])\n",
    "    df = df.join(q_price_aggs, on=\"query_id\", how=\"left\")\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"price_clip\") / (pl.col(\"q_price_median\")+1)).alias(\"price_vs_median_query\"),\n",
    "        ((pl.col(\"price_clip\") - pl.col(\"q_price_mean\"))/(pl.col(\"q_price_std\")+1e-6)).alias(\"price_z_in_query\"),\n",
    "        pl.col(\"price_clip\").rank(method=\"ordinal\").over(\"query_id\").alias(\"price_rank_in_query\"),\n",
    "        (pl.col(\"cos_q_title\") - pl.col(\"max_cos_in_query\")).alias(\"cos_minus_max\"),\n",
    "    ])\n",
    "\n",
    "    # поведение: conv -1 → NaN → фичи\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"item_query_click_conv\") != -1).alias(\"conv_known\"),\n",
    "        pl.when(pl.col(\"item_query_click_conv\")==-1).then(None).otherwise(pl.col(\"item_query_click_conv\")).alias(\"conv_raw\")\n",
    "    ])\n",
    "    q_conv_aggs = df.group_by(\"query_id\").agg([\n",
    "        pl.col(\"conv_raw\").mean().alias(\"q_conv_mean\"),\n",
    "        pl.col(\"conv_raw\").std(ddof=0).fill_null(0.0).alias(\"q_conv_std\"),\n",
    "    ])\n",
    "    df = df.join(q_conv_aggs, on=\"query_id\", how=\"left\")\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"conv_raw\").fill_null(0.0).alias(\"conv_filled\"),\n",
    "        ((pl.col(\"conv_raw\") - pl.col(\"q_conv_mean\"))/(pl.col(\"q_conv_std\")+1e-6)).alias(\"conv_z_in_query\"),\n",
    "        pl.col(\"conv_raw\").fill_null(-1.0).rank(method=\"ordinal\").over(\"query_id\").alias(\"conv_rank_in_query\"),\n",
    "    ])\n",
    "\n",
    "    # интеракции (часть дубля ниже переопределится новыми версиями — ок)\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"same_cat\").cast(pl.Float32) * pl.col(\"cos_q_title\")).alias(\"same_cat__cos\"),\n",
    "        (pl.col(\"same_loc\").cast(pl.Float32) * pl.col(\"cos_q_title\")).alias(\"same_loc__cos\"),\n",
    "        (pl.col(\"conv_filled\") * pl.col(\"cos_q_title\")).alias(\"conv__cos\"),\n",
    "        (pl.col(\"conv_filled\") * pl.col(\"same_loc\")).alias(\"conv__same_loc\"),\n",
    "        (pl.col(\"price_rank_in_query\") * pl.col(\"same_loc\")).alias(\"price_rank__same_loc\"),\n",
    "    ])\n",
    "\n",
    "    return df"
   ],
   "id": "799d02043748aa1c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T16:48:48.841667Z",
     "start_time": "2025-09-19T16:48:48.733695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============== Build ==============\n",
    "\n",
    "train_lf = pl.scan_parquet(TRAIN_PATH)\n",
    "test_lf  = pl.scan_parquet(TEST_PATH)\n",
    "\n",
    "freqs = build_global_freqs(\n",
    "    train_lf.select([\"item_cat_id\",\"item_mcat_id\",\"item_loc\"]),\n",
    "    test_lf.select([\"item_cat_id\",\"item_mcat_id\",\"item_loc\"])\n",
    ")\n"
   ],
   "id": "5b3583ffde9040e3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_18664\\4179544342.py:7: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  \"cat\":  freq_cat.collect(streaming=True),\n",
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_18664\\4179544342.py:8: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  \"mcat\": freq_mcat.collect(streaming=True),\n",
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_18664\\4179544342.py:9: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  \"loc\":  freq_loc.collect(streaming=True)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T16:49:03.415913Z",
     "start_time": "2025-09-19T16:48:56.740345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# collect bases\n",
    "test_base  = test_lf.collect(streaming=True)\n",
    "train_base = train_lf.collect(streaming=True)"
   ],
   "id": "7a75235f8c1ecabe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_18664\\2091646473.py:2: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  test_base  = test_lf.collect(streaming=True)\n",
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_18664\\2091646473.py:3: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  train_base = train_lf.collect(streaming=True)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T16:49:10.784607Z",
     "start_time": "2025-09-19T16:49:05.309808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# text feats\n",
    "test_txt  = add_text_feats(test_base)\n",
    "train_txt = add_text_feats(train_base)"
   ],
   "id": "bd3e0c33cdeae025",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T16:49:12.090476Z",
     "start_time": "2025-09-19T16:49:11.967630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cosines\n",
    "train_cos = pl.read_parquet(TRAIN_COS)\n",
    "test_cos  = pl.read_parquet(TEST_COS)"
   ],
   "id": "8bbfd32384e06466",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T16:49:22.686422Z",
     "start_time": "2025-09-19T16:49:19.090915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# basic + price/behavior/interactions/groups\n",
    "train_feats = add_basic_feats(train_txt, train_cos, freqs)\n",
    "test_feats  = add_basic_feats(test_txt,  test_cos,  freqs)\n",
    "\n",
    "print(\"[base feats] train:\", train_feats.shape, \"test:\", test_feats.shape)"
   ],
   "id": "6090dec07c7886ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[base feats] train: (7781790, 60) test: (335348, 59)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T16:52:07.840441Z",
     "start_time": "2025-09-19T16:52:06.999281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============== FAST BOOSTER FEATS ==============\n",
    "\n",
    "# 1) COS: per-query нормировки/ранги/гэп + интеракции\n",
    "q_cos_aggs = (\n",
    "    train_feats.group_by(\"query_id\")\n",
    "    .agg([\n",
    "        pl.col(\"cos_q_title\").mean().alias(\"q_cos_mean\"),\n",
    "        pl.col(\"cos_q_title\").std(ddof=0).fill_null(0.0).alias(\"q_cos_std\"),\n",
    "        pl.col(\"cos_q_title\").top_k(3).alias(\"__top3\"),\n",
    "    ])\n",
    "    .with_columns(pl.col(\"__top3\").list.eval(pl.element().cast(pl.Float32)).alias(\"__top3\"))\n",
    "    .with_columns(pl.col(\"__top3\").list.mean().alias(\"q_cos_top3_mean\"))\n",
    "    .drop(\"__top3\")\n",
    ")\n",
    "# COS агрегаты по train (для top3 mean). Они уже у вас посчитаны выше:\n",
    "# q_cos_aggs = (train_feats.groupby(\"query_id\") ...)\n",
    "\n",
    "for name in [\"train_feats\", \"test_feats\"]:\n",
    "    df = locals()[name]\n",
    "\n",
    "    # 1) per-query mean/std как оконные фичи (без join)\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"cos_q_title\").mean().over(\"query_id\").alias(\"q_cos_mean\"),\n",
    "        pl.col(\"cos_q_title\").std(ddof=0).fill_null(0.0).over(\"query_id\").alias(\"q_cos_std\"),\n",
    "    ])\n",
    "\n",
    "    # 2) per-query среднее top-3 косинусов:\n",
    "    #    сортируем по query_id и cos убыв., затем аггрегируем head(3).mean()\n",
    "    q_top3 = (\n",
    "        df.sort([\"query_id\", \"cos_q_title\"], descending=[False, True])\n",
    "          .group_by(\"query_id\")\n",
    "          .agg(\n",
    "              pl.col(\"cos_q_title\").head(3).mean().alias(\"q_cos_top3_mean\")\n",
    "          )\n",
    "    )\n",
    "\n",
    "    # 3) join агрегата top3 назад\n",
    "    df = df.join(q_top3, on=\"query_id\", how=\"left\")\n",
    "\n",
    "    # 4) производные cos-фичи\n",
    "    df = df.with_columns([\n",
    "        ((pl.col(\"cos_q_title\") - pl.col(\"q_cos_mean\")) / (pl.col(\"q_cos_std\") + 1e-6)).alias(\"cos_z_in_query\"),\n",
    "        pl.col(\"cos_q_title\").rank(method=\"ordinal\").over(\"query_id\").alias(\"cos_rank_in_query\"),\n",
    "        (pl.col(\"cos_q_title\") - pl.col(\"q_cos_top3_mean\")).alias(\"cos_gap_top3\"),\n",
    "    ])\n",
    "\n",
    "    # 5) интеракции (теперь колонки уже существуют)\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"same_loc\").cast(pl.Float32) * pl.col(\"cos_q_title\")).alias(\"same_loc__cos\"),\n",
    "        (pl.col(\"same_cat\").cast(pl.Float32) * pl.col(\"cos_q_title\")).alias(\"same_cat__cos\"),\n",
    "        (pl.col(\"same_loc\").cast(pl.Float32) * pl.col(\"cos_z_in_query\")).alias(\"cosz__same_loc\"),\n",
    "        (pl.col(\"same_cat\").cast(pl.Float32) * pl.col(\"cos_rank_in_query\").cast(pl.Float32)).alias(\"cosrank__same_cat\"),\n",
    "    ])\n",
    "\n",
    "    locals()[name] = df\n",
    "\n"
   ],
   "id": "c45a0a86123153b1",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 25\u001B[0m\n\u001B[0;32m     19\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlocals\u001B[39m()[name]\u001B[38;5;241m.\u001B[39mwith_columns([\n\u001B[0;32m     20\u001B[0m     pl\u001B[38;5;241m.\u001B[39mcol(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcos_q_title\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39mover(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery_id\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mq_cos_mean\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m     21\u001B[0m     pl\u001B[38;5;241m.\u001B[39mcol(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcos_q_title\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mstd(ddof\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mfill_null(\u001B[38;5;241m0.0\u001B[39m)\u001B[38;5;241m.\u001B[39mover(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery_id\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mq_cos_std\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m     22\u001B[0m ])\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# top3 mean через groupby+join (у окон пока нет top_k)\u001B[39;00m\n\u001B[0;32m     24\u001B[0m q_top3 \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m---> 25\u001B[0m     \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupby\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery_id\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     26\u001B[0m       \u001B[38;5;241m.\u001B[39magg(pl\u001B[38;5;241m.\u001B[39mcol(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcos_q_title\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mtop_k(\u001B[38;5;241m3\u001B[39m)\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__top3\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m     27\u001B[0m       \u001B[38;5;241m.\u001B[39mwith_columns(pl\u001B[38;5;241m.\u001B[39mcol(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__top3\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mlist\u001B[38;5;241m.\u001B[39meval(pl\u001B[38;5;241m.\u001B[39melement()\u001B[38;5;241m.\u001B[39mcast(pl\u001B[38;5;241m.\u001B[39mFloat32)))\n\u001B[0;32m     28\u001B[0m       \u001B[38;5;241m.\u001B[39mwith_columns(pl\u001B[38;5;241m.\u001B[39mcol(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__top3\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mlist\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mq_cos_top3_mean\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m     29\u001B[0m       \u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__top3\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     30\u001B[0m )\n\u001B[0;32m     31\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mjoin(q_top3, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m# производные\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'groupby'"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a8d8b15ab6230018"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
