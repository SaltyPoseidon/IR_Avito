{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f0d266",
   "metadata": {},
   "source": [
    "\n",
    "# 03 — Сборка фичей → LightGBM реранкер → сабмит (оптимизировано)\n",
    "- Сборка по ключу `['query_id','item_id']` через **Polars Lazy** (минимум памяти, один `collect(streaming=True)`).\n",
    "- Быстрый QC: *coverage* без materialize anti-join, *non-finite* за один проход.\n",
    "- Обучение `LightGBM LGBMRanker (lambdarank)` с hold-out по `query_id` и отчётом кастомного `NDCG@10` (`0.97^pos`).\n",
    "- Сабмит `solution.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5ac3178a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:43:45.325743Z",
     "start_time": "2025-09-24T20:43:45.314795Z"
    }
   },
   "source": [
    "\n",
    "##%%\n",
    "# Требования:\n",
    "# pip install polars pyarrow lightgbm tqdm numpy\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "31078523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:43:46.485818Z",
     "start_time": "2025-09-24T20:43:45.330743Z"
    }
   },
   "source": [
    "\n",
    "##%%\n",
    "import os, json, math\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ML\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    HAS_LGBM = True\n",
    "except Exception as e:\n",
    "    HAS_LGBM = False\n",
    "    print(\"[warn] LightGBM не установлен:\", e)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idine\\PycharmProjects\\Avito_Test\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "153e48fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:43:46.548007Z",
     "start_time": "2025-09-24T20:43:46.536357Z"
    }
   },
   "source": [
    "\n",
    "##%%\n",
    "# ---- Поиск корня проекта ----\n",
    "def find_project_root(start=None):\n",
    "    cur = os.path.abspath(start or os.getcwd())\n",
    "    while True:\n",
    "        has_data = os.path.isdir(os.path.join(cur, \"Data\"))\n",
    "        has_feat = os.path.isdir(os.path.join(cur, \"Features\"))\n",
    "        if has_data and has_feat:\n",
    "            return cur\n",
    "        parent = os.path.dirname(cur)\n",
    "        if parent == cur:\n",
    "            raise RuntimeError(\"Не нашёл корень проекта (ожидаю папки Data/ и Features/).\")\n",
    "        cur = parent\n",
    "\n",
    "BASE_DIR = find_project_root()\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"Data\")\n",
    "FEAT_DIR = os.path.join(BASE_DIR, \"Features\")\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, \"train-dset.parquet\")\n",
    "TEST_PATH  = os.path.join(DATA_DIR, \"test-dset-small.parquet\")\n",
    "\n",
    "TAB_DIR  = os.path.join(FEAT_DIR, \"table-basic\")\n",
    "COS_TIT_DIR_CAND = [\n",
    "    os.path.join(FEAT_DIR, \"cos-e5-small\"),\n",
    "    DATA_DIR,\n",
    "]\n",
    "COS_DESC_BASE_DIR = os.path.join(FEAT_DIR, \"cos-e5-base-desc\")\n",
    "\n",
    "def pick_cos_tit_dir():\n",
    "    for p in COS_TIT_DIR_CAND:\n",
    "        if os.path.exists(os.path.join(p, \"train_cos.parquet\")) and os.path.exists(os.path.join(p, \"test_cos.parquet\")):\n",
    "            return p\n",
    "    raise FileNotFoundError(\"Не нашёл train_cos.parquet/test_cos.parquet ни в Features/cos-e5-small, ни в Data/.\")\n",
    "\n",
    "COS_TIT_DIR = pick_cos_tit_dir()\n",
    "\n",
    "print(\"[paths]\")\n",
    "print(\"BASE_DIR =\", BASE_DIR)\n",
    "print(\"DATA_DIR =\", DATA_DIR)\n",
    "print(\"FEAT_DIR =\", FEAT_DIR)\n",
    "print(\"TAB_DIR  =\", TAB_DIR)\n",
    "print(\"COS_TIT_DIR =\", COS_TIT_DIR)\n",
    "print(\"COS_DESC_BASE_DIR =\", COS_DESC_BASE_DIR)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[paths]\n",
      "BASE_DIR = C:\\Users\\idine\\PycharmProjects\\Avito_Test\n",
      "DATA_DIR = C:\\Users\\idine\\PycharmProjects\\Avito_Test\\Data\n",
      "FEAT_DIR = C:\\Users\\idine\\PycharmProjects\\Avito_Test\\Features\n",
      "TAB_DIR  = C:\\Users\\idine\\PycharmProjects\\Avito_Test\\Features\\table-basic\n",
      "COS_TIT_DIR = C:\\Users\\idine\\PycharmProjects\\Avito_Test\\Features\\cos-e5-small\n",
      "COS_DESC_BASE_DIR = C:\\Users\\idine\\PycharmProjects\\Avito_Test\\Features\\cos-e5-base-desc\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "9440b489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:43:49.768554Z",
     "start_time": "2025-09-24T20:43:46.559061Z"
    }
   },
   "source": [
    "# ---- Lazy источники ----\n",
    "\n",
    "KEYS = [\"query_id\", \"item_id\"]\n",
    "\n",
    "# базовые пары + таргет (train)\n",
    "train_base_lf = pl.scan_parquet(TRAIN_PATH).select([\"query_id\", \"item_id\", \"item_contact\"])\n",
    "test_base_lf = pl.scan_parquet(TEST_PATH).select([\"query_id\", \"item_id\"])\n",
    "\n",
    "# табличные фичи\n",
    "train_tab_lf = pl.scan_parquet(os.path.join(TAB_DIR, \"train_feats_tab.parquet\"))\n",
    "test_tab_lf = pl.scan_parquet(os.path.join(TAB_DIR, \"test_feats_tab.parquet\"))\n",
    "\n",
    "# косинус query-title\n",
    "train_cos_tit_lf = pl.scan_parquet(os.path.join(COS_TIT_DIR, \"train_cos.parquet\"))\n",
    "test_cos_tit_lf = pl.scan_parquet(os.path.join(COS_TIT_DIR, \"test_cos.parquet\"))\n",
    "\n",
    "# косинус query_base ↔ desc_base (опционально)\n",
    "has_desc_cos = (\n",
    "        os.path.exists(os.path.join(COS_DESC_BASE_DIR, \"train_cos_desc_base.parquet\")) and\n",
    "        os.path.exists(os.path.join(COS_DESC_BASE_DIR, \"test_cos_desc_base.parquet\"))\n",
    ")\n",
    "train_cos_desc_lf = (\n",
    "    pl.scan_parquet(os.path.join(COS_DESC_BASE_DIR, \"train_cos_desc_base.parquet\"))\n",
    "    .select(KEYS + [\"cos_q_desc_base\"])\n",
    "    if has_desc_cos else None\n",
    ")\n",
    "test_cos_desc_lf = (\n",
    "    pl.scan_parquet(os.path.join(COS_DESC_BASE_DIR, \"test_cos_desc_base.parquet\"))\n",
    "    .select(KEYS + [\"cos_q_desc_base\"])\n",
    "    if has_desc_cos else None\n",
    ")\n",
    "\n",
    "\n",
    "# ---- Вспомогательные функции ----\n",
    "\n",
    "def schema_keys(lf: pl.LazyFrame) -> set[str]:\n",
    "    return set(lf.collect_schema().keys())\n",
    "\n",
    "\n",
    "def norm_keys(lf: pl.LazyFrame, extra: list[str] | None = None) -> pl.LazyFrame:\n",
    "    \"\"\"Выбираем только реально существующие колонки и кастуем ключи к Int64.\"\"\"\n",
    "    want = (extra or []) + KEYS\n",
    "    have = schema_keys(lf)\n",
    "    cols = [c for c in want if c in have]  # защита от ColumnNotFoundError\n",
    "    lf = lf.select(cols)\n",
    "    # если ключей нет в наборе (редко), добавим их пустыми, чтобы каст не упал\n",
    "    if \"query_id\" not in cols and \"query_id\" in have:\n",
    "        lf = lf.with_columns(pl.col(\"query_id\"))\n",
    "    if \"item_id\" not in cols and \"item_id\" in have:\n",
    "        lf = lf.with_columns(pl.col(\"item_id\"))\n",
    "    # финальный каст ключей\n",
    "    return lf.with_columns(\n",
    "        pl.col(\"query_id\").cast(pl.Int64),\n",
    "        pl.col(\"item_id\").cast(pl.Int64),\n",
    "    )\n",
    "\n",
    "\n",
    "# после получения схем:\n",
    "train_tab_schema = train_tab_lf.collect_schema()\n",
    "test_tab_schema  = test_tab_lf.collect_schema()\n",
    "\n",
    "EXCLUDE = set(KEYS) | {\"item_contact\"}  # исключаем ключи и таргет\n",
    "\n",
    "num_cols_train = [c for c, t in train_tab_schema.items() if t.is_numeric() and c not in EXCLUDE]\n",
    "num_cols_test  = [c for c, t in  test_tab_schema.items()  if t.is_numeric() and c not in EXCLUDE]\n",
    "\n",
    "train_tab_lf = norm_keys(train_tab_lf, num_cols_train)\n",
    "test_tab_lf  = norm_keys(test_tab_lf,  num_cols_test)\n",
    "\n",
    "train_cos_tit_lf = norm_keys(train_cos_tit_lf, [\"cos_q_title\"])\n",
    "test_cos_tit_lf = norm_keys(test_cos_tit_lf, [\"cos_q_title\"])\n",
    "\n",
    "train_base_lf = norm_keys(train_base_lf, [\"item_contact\"])\n",
    "test_base_lf = norm_keys(test_base_lf)\n",
    "\n",
    "if has_desc_cos:\n",
    "    train_cos_desc_lf = norm_keys(train_cos_desc_lf, [\"cos_q_desc_base\"])\n",
    "    test_cos_desc_lf = norm_keys(test_cos_desc_lf, [\"cos_q_desc_base\"])\n",
    "\n",
    "# ---- Ленивые join'ы ----\n",
    "train_lf = (\n",
    "    train_base_lf\n",
    "    .join(train_tab_lf, on=KEYS, how=\"left\")\n",
    "    .join(train_cos_tit_lf, on=KEYS, how=\"left\")\n",
    ")\n",
    "test_lf = (\n",
    "    test_base_lf\n",
    "    .join(test_tab_lf, on=KEYS, how=\"left\")\n",
    "    .join(test_cos_tit_lf, on=KEYS, how=\"left\")\n",
    ")\n",
    "\n",
    "if has_desc_cos:\n",
    "    train_lf = train_lf.join(train_cos_desc_lf, on=KEYS, how=\"left\")\n",
    "    test_lf = test_lf.join(test_cos_desc_lf, on=KEYS, how=\"left\")\n",
    "\n",
    "# ---- Один сбор (streaming) ----\n",
    "train_full = train_lf.collect(streaming=True)\n",
    "test_full = test_lf.collect(streaming=True)\n",
    "\n",
    "print(\"[assembled] train_full:\", train_full.shape, \"test_full:\", test_full.shape)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_27440\\3300283677.py:97: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  train_full = train_lf.collect(streaming=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[assembled] train_full: (7781790, 49) test_full: (335348, 48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_27440\\3300283677.py:98: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  test_full = test_lf.collect(streaming=True)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "2761469d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:43:50.546243Z",
     "start_time": "2025-09-24T20:43:49.804980Z"
    }
   },
   "source": [
    "\n",
    "##%%\n",
    "# ---- QC: быстрый coverage и non-finite ----\n",
    "\n",
    "def coverage_count(pairs: pl.DataFrame, feats: pl.DataFrame, name: str):\n",
    "    found = (\n",
    "        pairs.select(KEYS)\n",
    "             .join(feats.select(KEYS).with_columns(pl.lit(1).alias(\"__hit\")),\n",
    "                   on=KEYS, how=\"left\")\n",
    "             .select(pl.col(\"__hit\").is_null().sum().alias(\"missing\"))\n",
    "             .item()\n",
    "    )\n",
    "    print(f\"[coverage] {name}: missing pairs =\", found)\n",
    "\n",
    "# источники пар\n",
    "train_pairs = pl.scan_parquet(TRAIN_PATH).select(KEYS).collect(streaming=True)\n",
    "test_pairs  = pl.scan_parquet(TEST_PATH ).select(KEYS).collect(streaming=True)\n",
    "\n",
    "coverage_count(train_pairs, train_full, \"train\")\n",
    "coverage_count(test_pairs,  test_full,  \"test\")\n",
    "\n",
    "def non_finite_report_fast(df: pl.DataFrame, name: str, limit_print=20):\n",
    "    num_cols = [c for c,t in df.schema.items() if t.is_numeric() and c not in (\"query_id\",\"item_id\",\"item_contact\")]\n",
    "    if not num_cols:\n",
    "        print(f\"[non-finite] {name}: нет числовых фич\")\n",
    "        return\n",
    "    res = df.select([(~pl.col(c).is_finite()).sum().alias(c) for c in num_cols])\n",
    "    bad = res.melt(variable_name=\"col\", value_name=\"bad\").sort(\"bad\", descending=True).filter(pl.col(\"bad\") > 0)\n",
    "    if bad.height == 0:\n",
    "        print(f\"[non-finite] {name}: всё ок\")\n",
    "    else:\n",
    "        print(f\"[non-finite] {name}: проблемные колонки (первые {limit_print})\")\n",
    "        print(bad.head(limit_print))\n",
    "\n",
    "non_finite_report_fast(train_full, \"train\")\n",
    "non_finite_report_fast(test_full,  \"test\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_27440\\315490232.py:15: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  train_pairs = pl.scan_parquet(TRAIN_PATH).select(KEYS).collect(streaming=True)\n",
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_27440\\315490232.py:16: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  test_pairs  = pl.scan_parquet(TEST_PATH ).select(KEYS).collect(streaming=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[coverage] train: missing pairs = 0\n",
      "[coverage] test: missing pairs = 0\n",
      "[non-finite] train: всё ок\n",
      "[non-finite] test: всё ок\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_27440\\315490232.py:27: DeprecationWarning: `DataFrame.melt` is deprecated; use `DataFrame.unpivot` instead, with `index` instead of `id_vars` and `on` instead of `value_vars`\n",
      "  bad = res.melt(variable_name=\"col\", value_name=\"bad\").sort(\"bad\", descending=True).filter(pl.col(\"bad\") > 0)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "094d24b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:43:51.083013Z",
     "start_time": "2025-09-24T20:43:50.553363Z"
    }
   },
   "source": [
    "# ---- Подготовка матриц для LGBM ----\n",
    "drop_cols = {\"query_id\", \"item_id\", \"item_contact\"}\n",
    "\n",
    "train_num = {c for c, t in train_full.schema.items() if t.is_numeric() and c not in drop_cols}\n",
    "test_num  = {c for c, t in  test_full.schema.items() if t.is_numeric() and c not in drop_cols}\n",
    "\n",
    "# пересечение (на случай item_contact_right и пр.)\n",
    "feat_cols = [c for c in train_num & test_num]\n",
    "\n",
    "def sanitize(df: pl.DataFrame, cols: list[str]) -> np.ndarray:\n",
    "    X = df.select([pl.col(c).cast(pl.Float32).fill_null(0.0).alias(c) for c in cols]).to_numpy()\n",
    "    X[~np.isfinite(X)] = 0.0\n",
    "    return X.astype(np.float32, copy=False)\n",
    "\n",
    "X_train = sanitize(train_full, feat_cols)\n",
    "y_train = train_full.get_column(\"item_contact\").to_numpy().astype(np.int32)\n",
    "qids    = train_full.get_column(\"query_id\").to_numpy()\n",
    "X_test  = sanitize(test_full, feat_cols)\n",
    "\n",
    "print(\"[matrix] X_train:\", X_train.shape, \"X_test:\", X_test.shape, \"features:\", len(feat_cols))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[matrix] X_train: (7781790, 46) X_test: (335348, 46) features: 46\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "34c8efdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:43:55.640857Z",
     "start_time": "2025-09-24T20:43:51.089157Z"
    }
   },
   "source": [
    "\n",
    "##%%\n",
    "# ---- Hold-out по query_id ----\n",
    "rng = np.random.default_rng(42)\n",
    "uniq_q = np.unique(qids); rng.shuffle(uniq_q)\n",
    "n_val = max(1, int(0.1 * len(uniq_q)))\n",
    "val_set = set(uniq_q[:n_val])\n",
    "\n",
    "val_mask = np.isin(qids, list(val_set))\n",
    "tr_mask  = ~val_mask\n",
    "\n",
    "tr_idx = np.where(tr_mask)[0]\n",
    "va_idx = np.where(val_mask)[0]\n",
    "tr_idx = tr_idx[np.argsort(qids[tr_idx], kind=\"mergesort\")]\n",
    "va_idx = va_idx[np.argsort(qids[va_idx], kind=\"mergesort\")]\n",
    "\n",
    "X_tr, y_tr, q_tr = X_train[tr_idx], y_train[tr_idx], qids[tr_idx]\n",
    "X_va, y_va, q_va = X_train[va_idx], y_train[va_idx], qids[va_idx]\n",
    "\n",
    "def group_sizes_from_sorted_ids(ids: np.ndarray) -> np.ndarray:\n",
    "    _, counts = np.unique(ids, return_counts=True)\n",
    "    return counts.astype(int)\n",
    "\n",
    "tr_groups = group_sizes_from_sorted_ids(q_tr)\n",
    "va_groups = group_sizes_from_sorted_ids(q_va)\n",
    "\n",
    "print(f\"[split] train rows={X_tr.shape[0]}, val rows={X_va.shape[0]}, queries train/val={len(np.unique(q_tr))}/{len(np.unique(q_va))}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[split] train rows=7006773, val rows=775017, queries train/val=610371/67819\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "ff906283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:43:55.693585Z",
     "start_time": "2025-09-24T20:43:55.681279Z"
    }
   },
   "source": [
    "\n",
    "##%%\n",
    "# ---- Кастомный NDCG@10 (0.97^pos) ----\n",
    "def calc_dcg_at_k(v: np.ndarray, k: int = 10) -> float:\n",
    "    w = 0.97 ** np.arange(len(v))\n",
    "    return float((v * w)[:k].sum())\n",
    "\n",
    "def calc_ndcg_at_k(labels: np.ndarray, preds: np.ndarray, groups: np.ndarray, k: int = 10) -> float:\n",
    "    order = np.argsort(groups, kind=\"mergesort\")\n",
    "    labels, preds, groups = labels[order], preds[order], groups[order]\n",
    "    uq, counts = np.unique(groups, return_counts=True)\n",
    "    s = 0\n",
    "    scores = []\n",
    "    for c in counts:\n",
    "        sl = slice(s, s+c)\n",
    "        l = labels[sl]; p = preds[sl]\n",
    "        idx = np.argsort(-p, kind=\"mergesort\")\n",
    "        idcg = calc_dcg_at_k(np.sort(l)[::-1], k) + 1e-12\n",
    "        scores.append(calc_dcg_at_k(l[idx], k) / idcg)\n",
    "        s += c\n",
    "    return float(np.mean(scores)) if scores else 0.0\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "dc2d109d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:46:15.728865Z",
     "start_time": "2025-09-24T20:43:55.697693Z"
    }
   },
   "source": [
    "\n",
    "##%%\n",
    "# ---- Обучение LGBM ----\n",
    "if not HAS_LGBM:\n",
    "    raise RuntimeError(\"LightGBM недоступен в окружении. Установи пакет lightgbm.\")\n",
    "\n",
    "params = dict(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[10],\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=127,\n",
    "    min_data_in_leaf=100,\n",
    "    feature_fraction=0.9,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    verbose=-1,\n",
    "    seed=42,\n",
    "    device_type=\"cpu\",  # \"gpu\" если есть GPU-версия LGBM\n",
    ")\n",
    "\n",
    "dtr = lgb.Dataset(X_tr, label=y_tr, group=tr_groups, feature_name=feat_cols)\n",
    "dva = lgb.Dataset(X_va, label=y_va, group=va_groups, feature_name=feat_cols, reference=dtr)\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    dtr,\n",
    "    valid_sets=[dva],\n",
    "    num_boost_round=3000,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(100, verbose=False),\n",
    "        lgb.log_evaluation(100),\n",
    "    ],\n",
    ")\n",
    "print(\"[train] best_iteration:\", model.best_iteration)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's ndcg@10: 0.88796\n",
      "[200]\tvalid_0's ndcg@10: 0.889113\n",
      "[300]\tvalid_0's ndcg@10: 0.889281\n",
      "[400]\tvalid_0's ndcg@10: 0.889521\n",
      "[500]\tvalid_0's ndcg@10: 0.88967\n",
      "[600]\tvalid_0's ndcg@10: 0.889788\n",
      "[700]\tvalid_0's ndcg@10: 0.889844\n",
      "[800]\tvalid_0's ndcg@10: 0.890122\n",
      "[900]\tvalid_0's ndcg@10: 0.890087\n",
      "[train] best_iteration: 830\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "8ca3ba8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:46:34.941093Z",
     "start_time": "2025-09-24T20:46:31.241942Z"
    }
   },
   "source": [
    "\n",
    "##%%\n",
    "# ---- Валидация кастомным NDCG@10 ----\n",
    "preds_va = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "ndcg_val = calc_ndcg_at_k(y_va.astype(float), preds_va.astype(float), q_va, k=10)\n",
    "print(f\"[holdout] custom NDCG@10 (0.97^pos) = {ndcg_val:.5f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[holdout] custom NDCG@10 (0.97^pos) = 0.30772\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "908596c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:46:41.060214Z",
     "start_time": "2025-09-24T20:46:39.025703Z"
    }
   },
   "source": [
    "\n",
    "##%%\n",
    "# ---- Предсказания и сабмит ----\n",
    "test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "sub = test_full.select([\"query_id\",\"item_id\"]).with_columns(\n",
    "    pl.Series(\"pred\", test_pred)\n",
    ").sort([\"query_id\",\"pred\"], descending=[False, True]).select([\"query_id\",\"item_id\"])\n",
    "\n",
    "SUB_PATH = os.path.join(BASE_DIR, \"solution.csv\")\n",
    "sub.write_csv(SUB_PATH, include_header=True)\n",
    "print(\"[save] submission ->\", SUB_PATH, \"rows=\", sub.height)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save] submission -> C:\\Users\\idine\\PycharmProjects\\Avito_Test\\solution.csv rows= 335348\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:52:50.696405Z",
     "start_time": "2025-09-24T20:52:50.688279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- Кастомная метрика ndcg97@10 для LightGBM ----\n",
    "def _dcg_decay97(rel_sorted: np.ndarray, k: int = 10) -> float:\n",
    "    # Уже отсортированный по убыванию релевантности вектор\n",
    "    n = min(k, rel_sorted.shape[0])\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    w = (0.97 ** np.arange(n)).astype(np.float64)\n",
    "    return float((rel_sorted[:n] * w).sum())\n",
    "\n",
    "\n",
    "def _ndcg97_for_group(labels: np.ndarray, scores: np.ndarray, k: int = 10) -> float:\n",
    "    if labels.size == 0:\n",
    "        return 0.0\n",
    "    # предсказанное ранжирование\n",
    "    order = np.argsort(-scores, kind=\"mergesort\")\n",
    "    dcg = _dcg_decay97(labels[order], k)\n",
    "    # идеальное ранжирование\n",
    "    idcg = _dcg_decay97(np.sort(labels)[::-1], k)\n",
    "    return 0.0 if idcg <= 1e-12 else (dcg / idcg)\n",
    "\n",
    "\n",
    "def feval_ndcg97_at_10(preds: np.ndarray, train_dataset: \"lgb.Dataset\"):\n",
    "    \"\"\"LightGBM feval: возвращает средний ndcg97@10 по группам.\"\"\"\n",
    "    y = train_dataset.get_label().astype(np.float64, copy=False)\n",
    "    group = train_dataset.get_group()  # размеры групп в порядке следования строк\n",
    "    assert group is not None, \"group sizes are required for lambdarank\"\n",
    "    out = []\n",
    "    s = 0\n",
    "    for g in group:\n",
    "        e = s + int(g)\n",
    "        out.append(_ndcg97_for_group(y[s:e], preds[s:e], k=10))\n",
    "        s = e\n",
    "    val = float(np.mean(out)) if out else 0.0\n",
    "    # (name, value, higher_is_better)\n",
    "    return (\"ndcg97@10\", val, True)"
   ],
   "id": "90153ac0da0faf08",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:59:37.532588Z",
     "start_time": "2025-09-24T20:53:29.920453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- Обучение LGBM по ndcg97@10 ----\n",
    "if not HAS_LGBM:\n",
    "    raise RuntimeError(\"LightGBM недоступен. Установи пакет lightgbm.\")\n",
    "\n",
    "params = dict(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"None\",            # отключаем встроенную метрику\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=127,\n",
    "    min_data_in_leaf=100,\n",
    "    feature_fraction=0.9,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    verbose=-1,\n",
    "    seed=42,\n",
    "    device_type=\"gpu\",\n",
    ")\n",
    "\n",
    "dtr = lgb.Dataset(X_tr, label=y_tr, group=tr_groups, feature_name=feat_cols)\n",
    "dva = lgb.Dataset(X_va, label=y_va, group=va_groups, feature_name=feat_cols, reference=dtr)\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    dtr,\n",
    "    num_boost_round=4000,\n",
    "    valid_sets=[dva],                 # <-- только Dataset\n",
    "    valid_names=[\"valid\"],            # <-- имя отдельно\n",
    "    feval=feval_ndcg97_at_10,         # кастомная метрика (0.97^rank)\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(150, verbose=False),  # остановка по ndcg97@10\n",
    "        lgb.log_evaluation(100),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"[train] best_iteration:\", model.best_iteration)\n",
    "preds_va = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "ndcg_val = calc_ndcg_at_k(y_va.astype(float), preds_va.astype(float), q_va, k=10)\n",
    "print(f\"[holdout] ndcg97@10 = {ndcg_val:.5f}\")\n"
   ],
   "id": "8decae56915b2a4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid's ndcg97@10: 0.306207\n",
      "[200]\tvalid's ndcg97@10: 0.306635\n",
      "[300]\tvalid's ndcg97@10: 0.306797\n",
      "[400]\tvalid's ndcg97@10: 0.306835\n",
      "[train] best_iteration: 256\n",
      "[holdout] ndcg97@10 = 0.30701\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "assert HAS_LGBM, \"LightGBM недоступен. Установи пакет lightgbm.\"\n",
    "\n",
    "# 1) забираем лучшее число итераций с валидации\n",
    "best_iter = int(model.best_iteration or 1000)\n",
    "print(f\"[full-train] using best_iter = {best_iter}\")\n",
    "\n",
    "# 2) склеиваем train+valid (важно: в исходном порядке по группам)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_all = np.vstack([X_tr, X_va])            # если это pd.DataFrame — используй pd.concat([X_tr, X_va])\n",
    "y_all = np.concatenate([y_tr, y_va])\n",
    "groups_all = np.concatenate([tr_groups, va_groups])\n",
    "\n",
    "# 3) собираем Dataset и переобучаем без early stopping\n",
    "params_full = dict(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"None\",\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=127,\n",
    "    min_data_in_leaf=100,\n",
    "    feature_fraction=0.9,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    verbose=-1,\n",
    "    seed=42,\n",
    "    device_type=\"gpu\",\n",
    ")\n",
    "\n",
    "dall = lgb.Dataset(X_all, label=y_all, group=groups_all, feature_name=feat_cols)\n",
    "\n",
    "final_model = lgb.train(\n",
    "    params_full,\n",
    "    dall,\n",
    "    num_boost_round=best_iter,     # фиксируем число итераций\n",
    "    valid_sets=[],                 # без валидации\n",
    "    feval=None,                    # кастомная метрика не нужна здесь\n",
    "    callbacks=[lgb.log_evaluation(200)],\n",
    ")\n",
    "\n",
    "print(\"[full-train] done. num_trees:\", final_model.num_trees())\n",
    "\n",
    "# 4) предсказываем на тесте\n",
    "preds_te = final_model.predict(X_te, num_iteration=best_iter)\n",
    "\n",
    "# 5) формируем сабмит\n",
    "# Вариант A: если сабмит — просто скоры на каждую пару (qid, doc_id)\n",
    "sub = pd.DataFrame({\n",
    "    \"qid\": qid_te,            # подставь своё имя колонки с ID запроса\n",
    "    \"doc_id\": doc_ids_te,     # подставь своё имя колонки с ID документа\n",
    "    \"score\": preds_te.astype(float),\n",
    "})\n",
    "\n",
    "# Вариант B (если нужен ранжированный список или rank по каждому qid):\n",
    "# присвоим ранги внутри каждого qid по убыванию score\n",
    "sub[\"rank\"] = (\n",
    "    sub.groupby(\"qid\")[\"score\"]\n",
    "       .rank(method=\"first\", ascending=False)\n",
    "       .astype(int)\n",
    ")\n",
    "\n",
    "# если требуется top-10: оставляем rank<=10\n",
    "# sub_top10 = sub[sub[\"rank\"] <= 10].copy()\n",
    "\n",
    "# 6) сохраняем\n",
    "sub_path = \"submission_full.csv\"\n",
    "sub.to_csv(sub_path, index=False)\n",
    "print(f\"[submit] saved to {sub_path}\")"
   ],
   "id": "483bb80e72066edf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
