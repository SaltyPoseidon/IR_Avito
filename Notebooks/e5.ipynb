{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:41:03.417264Z",
     "start_time": "2025-09-19T00:40:58.633294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # 01 — E5-эмбеддинги (query_text & item_title) с сохранением\n",
    "# - Модель: intfloat/multilingual-e5-small (384d)\n",
    "# - Префиксы согласно e5: \"query: ...\" и \"passage: ...\"\n",
    "# - Сохранение: `memmap` (float16) + индексы **или** parquet-шарды\n",
    "# - Прогресс-бары: tqdm\n",
    "#\n",
    "# Требования:\n",
    "# pip install polars pyarrow sentence-transformers torch tqdm\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import List, Tuple\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer"
   ],
   "id": "cd71b431e3ece506",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idine\\PycharmProjects\\Avito_Test\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:42:14.063947Z",
     "start_time": "2025-09-19T00:42:14.059947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"Data\")\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, \"train-dset.parquet\")\n",
    "TEST_PATH  = os.path.join(DATA_DIR, \"test-dset-small.parquet\")"
   ],
   "id": "5e6c4a739562c6a6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:42:14.773752Z",
     "start_time": "2025-09-19T00:42:14.765754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"intfloat/multilingual-e5-small\"\n",
    "EMB_DIM    = 384  # для base будет 768\n",
    "\n",
    "# Режим сохранения: \"memmap\" или \"parquet\"\n",
    "SAVE_MODE  = \"memmap\""
   ],
   "id": "2ac7e3bf2a228ea7",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:42:14.945419Z",
     "start_time": "2025-09-19T00:42:14.943418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Директории для сохранения\n",
    "PARQUET_DIR = \"embeddings_parquet\"\n",
    "MEMMAP_DIR  = \"../Data/embeddings_memmap\""
   ],
   "id": "e9f7e075aa3abdd8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:42:15.147930Z",
     "start_time": "2025-09-19T00:42:15.132660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Параметры батчинга/шардирования\n",
    "BATCH_SIZE  = 1024          # для инференса модели\n",
    "SHARD_SIZE  = 250_000       # размер шарда при parquet-выгрузке\n",
    "\n",
    "# Рандом и девайс\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ],
   "id": "3e114ab2b50f0166",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:42:15.318576Z",
     "start_time": "2025-09-19T00:42:15.312577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ],
   "id": "fa2d8bb013805bc4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x208c4e984b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:42:15.505579Z",
     "start_time": "2025-09-19T00:42:15.494578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ## 1) Загрузка уникальных текстов (train + test)\n",
    "# - Уникализируем по `query_id` и `item_id`\n",
    "# - Берём соответствующие тексты: `query_text`, `item_title`\n",
    "\n",
    "# ленивые сканы\n",
    "train_lf = pl.scan_parquet(TRAIN_PATH)\n",
    "test_lf = pl.scan_parquet(TEST_PATH)"
   ],
   "id": "59a05450504ae9db",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:42:20.945183Z",
     "start_time": "2025-09-19T00:42:20.806359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# уникальные по query_id\n",
    "queries_uniques = (\n",
    "    pl.concat([\n",
    "        train_lf.select(\"query_id\", \"query_text\"),\n",
    "        test_lf.select(\"query_id\", \"query_text\"),\n",
    "    ])\n",
    "    .unique(subset=[\"query_id\"])\n",
    "    .collect(streaming=True)\n",
    ")\n"
   ],
   "id": "1a89cf15a5416519",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_44180\\1145090502.py:3: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  pl.concat([\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:49:02.342745Z",
     "start_time": "2025-09-19T00:49:01.252381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# уникальные по item_id\n",
    "items_uniques = (\n",
    "    pl.concat([\n",
    "        train_lf.select(\"item_id\", \"item_title\"),\n",
    "        test_lf.select(\"item_id\", \"item_title\"),\n",
    "    ])\n",
    "    .unique(subset=[\"item_id\"])\n",
    "    .collect(streaming=True)\n",
    ")"
   ],
   "id": "ccba9498f412015b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idine\\AppData\\Local\\Temp\\ipykernel_44180\\2638892594.py:3: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  pl.concat([\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:49:08.628913Z",
     "start_time": "2025-09-19T00:49:08.617914Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"[data] queries_uniques: {queries_uniques.shape}, items_uniques: {items_uniques.shape}\")",
   "id": "7892459694ed1eac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data] queries_uniques: (690695, 2), items_uniques: (5986464, 2)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:49:24.394198Z",
     "start_time": "2025-09-19T00:49:20.079564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ## 2) Инициализация e5-модели и функция кодирования\n",
    "# - Важно: e5 требует **префиксов** — `\"query:\"` и `\"passage:\"`\n",
    "# - `normalize_embeddings=True` ⇒ L2-норма = 1, значит `dot = cosine`\n",
    "\n",
    "model = SentenceTransformer(MODEL_NAME, device=DEVICE)"
   ],
   "id": "eb9824dd80ca566",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:49:24.502807Z",
     "start_time": "2025-09-19T00:49:24.485803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_texts(texts: List[str], prefix: str, batch_size: int = BATCH_SIZE) -> np.ndarray:\n",
    "    \"\"\"Кодируем список строк e5, добавляя нужный префикс. Возвращаем float32 L2-нормированные вектора.\"\"\"\n",
    "    prepped = [f\"{prefix} {t if t is not None else ''}\".strip() for t in texts]\n",
    "    embs = model.encode(\n",
    "        prepped,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=False,   # прогресс дадим внешним tqdm\n",
    "        normalize_embeddings=True, # L2-нормализация\n",
    "        convert_to_numpy=True,\n",
    "        device=DEVICE\n",
    "    ).astype(np.float32)\n",
    "    return embs"
   ],
   "id": "4f668f7860c53625",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:49:50.619395Z",
     "start_time": "2025-09-19T00:49:50.606399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ## 3A) Сохранение в Parquet (шарды)\n",
    "# Каждая строка: `id` + `embedding` (List[Float32])\n",
    "# - Плюсы: проще смотреть/джоинить\n",
    "# - Минусы: больше места на диске\n",
    "\n",
    "def to_parquet_shards(df_id_text: pl.DataFrame, id_col: str, text_col: str, prefix: str,\n",
    "                      out_dir: str, shard_size: int = SHARD_SIZE):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    n = df_id_text.height\n",
    "    n_shards = (n + shard_size - 1) // shard_size\n",
    "    print(f\"[parquet] {id_col}: {n} rows → {n_shards} shard(s)\")\n",
    "\n",
    "    # делаем детерминированный порядок по id (на всякий случай)\n",
    "    df_id_text = df_id_text.sort(id_col)\n",
    "\n",
    "    with tqdm(total=n, desc=f\"encode+save [{id_col}]\") as pbar:\n",
    "        for i in range(n_shards):\n",
    "            a, b = i * shard_size, min((i + 1) * shard_size, n)\n",
    "            part = df_id_text.slice(a, b - a)\n",
    "            texts = part.get_column(text_col).to_list()\n",
    "            embs = encode_texts(texts, prefix=prefix, batch_size=BATCH_SIZE)  # (m, d)\n",
    "\n",
    "            out = part.with_columns(pl.Series(\"embedding\", [list(v) for v in embs]))\n",
    "            out_path = os.path.join(out_dir, f\"{id_col}_emb_shard_{i:03d}.parquet\")\n",
    "            out.write_parquet(out_path)\n",
    "            pbar.update(b - a)\n",
    "            tqdm.write(f\"[parquet] saved shard {i + 1}/{n_shards}: {out_path} shape={out.shape}\")\n"
   ],
   "id": "da605ec81b0390ba",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T00:50:00.896944Z",
     "start_time": "2025-09-19T00:50:00.883946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ## 3B) Сохранение в np.memmap (float16) + индексы\n",
    "# - Плюсы: экономия диска (≈×2), быстрый случайный доступ, удобно в тренинге\n",
    "# - Сохраняем:\n",
    "#   - бинарный `.memmap` массив (N × D, float16)\n",
    "#   - `id2idx.json` — словарь для доступа по id\n",
    "\n",
    "def to_memmap(df_id_text: pl.DataFrame, id_col: str, text_col: str, prefix: str,\n",
    "              out_dir: str, dim: int = EMB_DIM, batch_size: int = BATCH_SIZE, fname_prefix: str = \"item\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # детерминированный порядок по id\n",
    "    df_id_text = df_id_text.sort(id_col)\n",
    "\n",
    "    ids = df_id_text.get_column(id_col).to_list()\n",
    "    texts = df_id_text.get_column(text_col).to_list()\n",
    "    N = len(ids)\n",
    "\n",
    "    mmap_path = os.path.join(out_dir, f\"{fname_prefix}_embeddings.f16.memmap\")\n",
    "    idmap_path = os.path.join(out_dir, f\"{fname_prefix}_id2idx.json\")\n",
    "\n",
    "    emb_mm = np.memmap(mmap_path, dtype=\"float16\", mode=\"w+\", shape=(N, dim))\n",
    "    id2idx = {}\n",
    "\n",
    "    with tqdm(total=N, desc=f\"encode+memmap [{fname_prefix}]\") as pbar:\n",
    "        for a in range(0, N, batch_size):\n",
    "            b = min(a + batch_size, N)\n",
    "            embs = encode_texts(texts[a:b], prefix=prefix, batch_size=batch_size)  # float32 normalized\n",
    "            emb_mm[a:b] = embs.astype(np.float16)\n",
    "            # индекс\n",
    "            for j, _id in enumerate(ids[a:b]):\n",
    "                id2idx[_id] = a + j\n",
    "            pbar.update(b - a)\n",
    "\n",
    "    emb_mm.flush()\n",
    "    with open(idmap_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(id2idx, f)\n",
    "\n",
    "    print(f\"[memmap] saved: {mmap_path} (shape=({N},{dim}), dtype=float16)\")\n",
    "    print(f\"[memmap] index: {idmap_path} (size={len(id2idx)})\")"
   ],
   "id": "e0657b6f6454376d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T02:30:31.502368Z",
     "start_time": "2025-09-19T00:50:17.132627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ## 4) Запуск сохранения (выберите режим)\n",
    "# - `SAVE_MODE = \"parquet\"`: будут сохранены шарды для query и item\n",
    "# - `SAVE_MODE = \"memmap\"`: будут сохранены 2 файла `.memmap` и 2 индекса `.json`\n",
    "\n",
    "if SAVE_MODE == \"parquet\":\n",
    "    os.makedirs(PARQUET_DIR, exist_ok=True)\n",
    "    # queries → parquet\n",
    "    to_parquet_shards(\n",
    "        queries_uniques,\n",
    "        id_col=\"query_id\",\n",
    "        text_col=\"query_text\",\n",
    "        prefix=\"query:\",\n",
    "        out_dir=os.path.join(PARQUET_DIR, \"queries\"),\n",
    "        shard_size=SHARD_SIZE\n",
    "    )\n",
    "    # items (titles) → parquet\n",
    "    to_parquet_shards(\n",
    "        items_uniques,\n",
    "        id_col=\"item_id\",\n",
    "        text_col=\"item_title\",\n",
    "        prefix=\"passage:\",\n",
    "        out_dir=os.path.join(PARQUET_DIR, \"items\"),\n",
    "        shard_size=SHARD_SIZE\n",
    "    )\n",
    "\n",
    "elif SAVE_MODE == \"memmap\":\n",
    "    os.makedirs(MEMMAP_DIR, exist_ok=True)\n",
    "    # queries → memmap\n",
    "    to_memmap(\n",
    "        queries_uniques,\n",
    "        id_col=\"query_id\",\n",
    "        text_col=\"query_text\",\n",
    "        prefix=\"query:\",\n",
    "        out_dir=MEMMAP_DIR,\n",
    "        dim=EMB_DIM,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        fname_prefix=\"query\"\n",
    "    )\n",
    "    # items (titles) → memmap\n",
    "    to_memmap(\n",
    "        items_uniques,\n",
    "        id_col=\"item_id\",\n",
    "        text_col=\"item_title\",\n",
    "        prefix=\"passage:\",\n",
    "        out_dir=MEMMAP_DIR,\n",
    "        dim=EMB_DIM,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        fname_prefix=\"item\"\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"SAVE_MODE must be 'parquet' or 'memmap'\")\n"
   ],
   "id": "f7c2bc748d876712",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encode+memmap [query]: 100%|██████████| 690695/690695 [06:55<00:00, 1663.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[memmap] saved: embeddings_memmap\\query_embeddings.f16.memmap (shape=(690695,384), dtype=float16)\n",
      "[memmap] index: embeddings_memmap\\query_id2idx.json (size=690695)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encode+memmap [item]: 100%|██████████| 5986464/5986464 [1:33:10<00:00, 1070.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[memmap] saved: embeddings_memmap\\item_embeddings.f16.memmap (shape=(5986464,384), dtype=float16)\n",
      "[memmap] index: embeddings_memmap\\item_id2idx.json (size=5986464)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "20f5ef812cd86d4c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
